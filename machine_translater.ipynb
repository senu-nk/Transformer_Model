{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d3vil-server/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-17 05:02:46.090590: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 05:02:46.191478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:\n",
      "2023-03-17 05:02:46.191495: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-17 05:02:46.835093: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:\n",
      "2023-03-17 05:02:46.835209: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:\n",
      "2023-03-17 05:02:46.835216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset preparatoin code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1)\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(\n",
    "        vocab_size, d_model, mask_zero=True)\n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask=True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model),\n",
    "        tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3880262/281493116.py:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 176,   47,   10,  760, 2089,  518,  294,    2,  104, 1823, 1987,\n",
       "         4449, 6593,    3,  805, 5243,   12,    1,    2,    1,  228,    2,\n",
       "         6095,   83,  864,   54,   52,   22,  102,    5,    2, 4348,  100,\n",
       "           35,   25,   38,  114, 1135,   12,    9,    7, 2287, 1150,    6,\n",
       "          449,   47,  537,    6,   93,   34,   23,   40,  935,  427,    1,\n",
       "           16,    2,  173,    6, 3009,   24,    1, 4660,   20,    4, 2940,\n",
       "           12,   43,   74,  223,   71,  123,    8,   78, 3122,  190,   20,\n",
       "          238,    3,    2,    1,  208, 4930,  144,   21,   62,   28,   16,\n",
       "            1,   81,  354,  294,    4,   19,   18,    9,  208,   26,  293,\n",
       "           12,    1,    1,   14,    2, 8617,    1,  116,  437,    3,    1,\n",
       "            1,   14,    2, 1570,    1,  640,   65,  405,  377,   10,   89,\n",
       "          117,   47,  111,  374,   34,    1,   36],\n",
       "        [  10,  112,   21,  103,    2,  418,   17,   10,   96,   21,  103,\n",
       "            2,  418,   17,   10, 2248,    2,  270,  101,  145,   16,  344,\n",
       "           33,  557,    3,   10, 1398,  246,  523,    5,  145,  520,    9,\n",
       "          586,  520,  156,  642,    2, 4061,   44,    5,    2,    1,   37,\n",
       "         4153,   90,  190, 1577,    3,  745,   18,    1,    1,   68,   60,\n",
       "           26, 1999,   14,    4, 1577,  574,   30,    4, 4153,    1,  435,\n",
       "            7,    1,    1,  317,  488,   99,  260,    6,   75,    2,  307,\n",
       "            6,  432,    2,  115,  180,    6,   26,   33, 1319,   16,  741,\n",
       "         1342,    1,    1,   36,   28,  129,    6,  157,    1,  308,    7,\n",
       "          321,    1,    3, 1435, 3950,   39,    1,   31,   24,  663, 6306,\n",
       "          210,  590,   14, 2085, 1342,    1,    7,  677,  111,  240,   70,\n",
       "          642,    4,  215,    9,    1,   22,  205],\n",
       "        [   4, 1323,  110,   66, 2760,    5,    1,    2, 1209,   16,  110,\n",
       "         4383, 2599,   20, 1684, 4009,    3,   85,   11,    7,  322,   32,\n",
       "         4362,   84,    6, 5497, 1343,    6,  243,   78,    2,   66, 2604,\n",
       "           20,    4,    1,   35,  474,   38,   71,    6,   26,    4, 2208,\n",
       "         1635,   14,   73,   14,    4,   49,  667,    3,  362,    4, 6265,\n",
       "         1420,    7,   51, 3370,    6,   87,   14,    2,   66, 4152,   72,\n",
       "           64,    2, 1293, 1834,    2, 2252,    8,   24,  923,  347, 1444,\n",
       "            3,   85,   27,    1,   15,    2, 1468,    1,   12,  406,   87,\n",
       "            4,  302,    3,  741,   66,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0],\n",
       "        [  11,    1, 3513,    1,    7,    4,  438, 4337,    1, 1887,   15,\n",
       "           33,    1,    1, 7735,    1,   35, 1051,    1,    6,  974,  124,\n",
       "           24,    1,    1,   32,    1,   46,    5,    2,    1,    1,   22,\n",
       "           76,  120, 4179,  122,  510,   20,    3,   35,   40,  587,    6,\n",
       "           26, 2922,    1,    2,    1,  229,   83,    1,    6,    1,    4,\n",
       "          166,    1, 1679,  778,   61,   60,  922,    8,   46, 1923,  960,\n",
       "         1136,    4, 3539,   61,  451,  765,  262,   33, 1367, 1895, 1385,\n",
       "           35,  451,  586, 1148,  558,   21,    6,  717,    4,    1,  754,\n",
       "          790,   44,    5,    2, 1420,    5,    1,  264,    8,   11,  413,\n",
       "            2,  107,    1, 5497, 2569,    1, 1485, 3486,    8,    2,  130,\n",
       "           10,  171,  125,  144,  740,   12,   11,   19,  255,   55, 1969,\n",
       "            5,    2, 8784,    5, 3930,    1,    1],\n",
       "        [  88,    5,   31,   10, 5458,  252,   12, 8509,   90,   23, 5488,\n",
       "          368,  123,   36,    2, 2227,  854,   95,    5,    2,  989,    3,\n",
       "          788,   90,   36,   11,  272,  152,  630,    6, 2757,    4,  221,\n",
       "            5, 1162,  804,  779, 1288,   65,   91,   90,   65,  152, 1799,\n",
       "            6,   75,  426,    3,  154,   14, 3217,    6,  200,  448, 2256,\n",
       "            3,    1,    2, 2149,    3,    1,  422,   62,   79,   90,   65,\n",
       "           91,   32,    4,  165, 1871,    5,  886,   17,  101,   17,   65,\n",
       "         6414,   32, 1337,    3,  248, 4071,    5,  290,    9,  850,    2,\n",
       "            1,  367,    1, 1315,   29,   40,  317,   21,  154,   21,  280,\n",
       "           21,  120,   18,    2,  146,    7,   72,  102,   29,  154,   82,\n",
       "           65,  322,    6, 8509,   90,    6,   26,  154,  256,   15,    4,\n",
       "          179,   37,   11,   15,    4,  166,   62]], dtype=int32),\n",
       " 39087    0\n",
       " 30893    0\n",
       " 45278    1\n",
       " 16398    0\n",
       " 13653    0\n",
       " Name: sentiment, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "# Pre-processing fucntions\n",
    "\n",
    "\n",
    "def clear_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "\n",
    "def clear_punctuations(text):\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "def sentiment_converter(text):\n",
    "    if text == \"positive\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# %% Pre-processing part 1\n",
    "\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(clear_html)\n",
    "df[\"review\"] = df[\"review\"].apply(clear_punctuations)\n",
    "df[\"sentiment\"] = df[\"sentiment\"].apply(sentiment_converter)\n",
    "df.head()\n",
    "\n",
    "# %% Pre-processing part2 tokenzing and spliting\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=10_000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df[\"review\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"review\"])\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences, maxlen=128, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    padded_sequences, df[\"sentiment\"], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train[0:5],y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=128,\n",
    "    target_vocab_size=1,\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "# print(X_train.shape)\n",
    "batch_size = 128\n",
    "# makae transformer.build to work\n",
    "\n",
    "# transformer.summary()\n",
    "# transformer.compile(optimizer=optimizer, loss=loss_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__train_step() missing 1 required positional argument: 'target'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     25\u001b[0m     \u001b[39mfor\u001b[39;00m (batch, (inputs, targets)) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataset):\n\u001b[0;32m---> 26\u001b[0m         train_step(inputs, targets)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__train_step() missing 1 required positional argument: 'target'\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_train, y_train)).shuffle(buffer_size=10000).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_val, y_val)).batch(batch_size)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, input, target):\n",
    "    # Forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(input)\n",
    "        loss = loss_object(target, predictions)\n",
    "\n",
    "    # Backward pass\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for (batch, (inputs, targets)) in enumerate(train_dataset):\n",
    "        train_step(inputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_3880262/2395128574.py\", line 5, in train_step  *\n        predictions = model(input)\n    File \"/home/d3vil-server/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer 'transformer_3' (type Transformer).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_3880262/3136393357.py\", line 20, in call  *\n            context, x = inputs\n    \n        OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n    \n    \n    Call arguments received by layer 'transformer_3' (type Transformer):\n      • inputs=tf.Tensor(shape=(64, 128), dtype=int32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Train loop\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m batch, (\u001b[39minput\u001b[39m, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataset):\n\u001b[0;32m---> 14\u001b[0m     loss \u001b[39m=\u001b[39m train_step(transformer, \u001b[39minput\u001b[39;49m, target)\n\u001b[1;32m     15\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[1;32m     16\u001b[0m     train_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1269\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1269\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1270\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1271\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_3880262/2395128574.py\", line 5, in train_step  *\n        predictions = model(input)\n    File \"/home/d3vil-server/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer 'transformer_3' (type Transformer).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_3880262/3136393357.py\", line 20, in call  *\n            context, x = inputs\n    \n        OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n    \n    \n    Call arguments received by layer 'transformer_3' (type Transformer):\n      • inputs=tf.Tensor(shape=(64, 128), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_train, y_train)).shuffle(buffer_size=10000).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (X_val, y_val)).batch(batch_size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_batches = 0\n",
    "    val_batches = 0\n",
    "\n",
    "    # Train loop\n",
    "    for batch, (input, target) in enumerate(train_dataset):\n",
    "        loss = train_step(transformer, input, target)\n",
    "        train_loss += loss\n",
    "        train_batches += 1\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Batch {batch}, Train Loss {loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    for batch, (input, target) in enumerate(val_dataset):\n",
    "        predictions = transformer(input, training=False)\n",
    "        loss = loss_object(target, predictions)\n",
    "        val_loss += loss\n",
    "        val_batches += 1\n",
    "\n",
    "    train_loss /= train_batches\n",
    "    val_loss /= val_batches\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}, Train Loss {train_loss:.4f}, Val Loss {val_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
